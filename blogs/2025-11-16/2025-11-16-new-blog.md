---
title: '2025년 블로그 재단장하기'
authors: [arch-spatula]
tags: ['cursor', 'node.js', 'blog', 'AI']
description: '더 많은 의존성을 줄이고 직접 개발자 블로그를 만들기로 함'
draft: true
date: 2025-11-16
---

<!-- 글쓰기 단계: 아이디어 -->

# 2025년 블로그 재단장하기

- 사실 nuxt만으로 만족을 할 수 없었습니다.
  - 결국 빌드는 깨졌습니다. 일부 블로그 글은 올릴 수 없었습니다.
  - 빌드가 깨지면 무슨 이유로 깨졌는지 알려줘야 하는데 nuxtContent도 결국 안 알려줬습니다.
  - `_draft`로 선언해야 하는 것도 마음에 안 들었습니다.
  - 제가 원하는 것은 매직이 아니라 이해가 되었습니다.
    - 빌드가 실패한다면 무슨 이유로 실패하고 어떻게 고쳐야 하는지 알고 싶습니다.
    - 숨겨진 제어흐름이 편리하지 않고 오히려 혼란을 가져왔습니다.
- 개발자 블로그를 다시 만들어도 최대한 단순하게 다시 만들고 싶다는 생각이 들었습니다.
  - 어떻게 하면 최대한 저에게 숨겨진 제어흐름을 제거하고 모든 부분을 잘 설계된 코드로 이해하며 만들고 싶었습니다.
- 블로그 자체도 결국 소프트웨어라고 생각한다면 코드의 수명을 40년 단위로 길게 봐야할 필요가 있다는 생각이 들었습니다.
  - 40년을 제가 생각하는 저의 개발자 커리어 기간입니다.

## 개발 전에 실험

- 이전에 [new-blog-2025](https://github.com/arch-spatula/new-blog-2025) 에서 개발자 블로그를 다시만든다면 어떻게 다시 만들지 실험을 했습니다.
  - vite를 사용했었는데 이 부분은 직접 블로그에서 수정을 시도하면서 실수였다는 생각이 들었습니다.
  - github pages에 공개할 것이면 높은 수준의 빌드 최적화가 필요한 것이 아닙니다.
  - 단순한 MPA로 처리해도 되었습니다.
  - vite로 MPA 스타일로 빌드를 처리하고자 했습니다. 이 부분은 올바른 선택이었습니다.
- 이 실험을 하기 위해서 neovim 에디터로 작업을 했습니다. ChatGPT에게 질문을 안 한 것은 아닙니다. 하지만 여전히 생산성은 낮았습니다.
  - 엄청 오래걸려야 할 작업이라고 생각해본다면 아닙니다.

### 맞춘 것

- 디자인을 다시했는데 다시 한 디자인이 올바른 것이었습니다.
  - nuxt로 마이그레이션 하면서 넣은 디자인은 상당히 마음에 안 들었습니다.
  - 새롭게 시도해보고자 하는 블로그는 [기계인간 John Grib](https://johngrib.github.io/) 의 레이아웃을 더욱더 적극적으로 표절했습니다.
    - 컬러 자체는 github 테마를 최대한 활용했습니다. 일관된 컬러는 적은 컬러이기 때문에 그렇습니다.
    - 의외로 콘텐츠 너비는 그렇게 까지 넓을 필요는 없었습니다.
    - 개발자 블로그를 많이 만들 때는 자주 참고하면서 생각을 바꾼 부분도 있습니다.
      - 경력이 있으면 본인의 업무랑 무관한 기술을 블로그 글에 작성해도 된다입니다. 누가 생각하기에는 당연하다고 보겠지만 전문성이라는 문제를 생각해보면 어느정도 자제해야 하는 것들이 맞습니다.
    - 블로그의 기능적인 것도 참고를 했습니다. 블로그를 더 편하게 사용하기 위해서는 단축키가 필요합니다.
    - [VitePress](https://vitepress.dev/)랑 같이 보고 저도 VitePress를 표절해서 검색 기능을 넣어주기로 했습니다.
- 의존성을 가능하면 많이 줄이는 것입니다.
- 검색은 ctrl + k로 숨겼다가 보여주는 것이 적절합니다.
  - nuxt로 만들었을 때는 상단에 항상 보였습니다. 태그가 생각보다 많은데 글 목록을 보기 위해 아래로 스크롤을 상당히 많이 내려줘야 했습니다.
- 상태 관리는 url에서 처리하는 것이 적절합니다.

![현재 블로그 검색](현재_블로그_검색.png)

- 여기서 태그가 더 많아지면 스크롤을 추가해야 합니다. 이중 스크롤 구조는 추할 것입니다.
- 모든 요소가 너무 넓습니다. 각 글마다 차지하는 공간이 너무 넓어 보입니다. 오히려 더 컴팩트해도 가독성을 유지할 수 있을 것입니다.

### 틀린 것

- vite를 사용해서 MPA를 빌드하려고 시도했습니다.
  - vite의 hook을 이해하고 빌드처리를 했어야 합니다. 없어도 될 복잡성이 었습니다.
  - vite의 hook을 이해해볼 수 있다는 것이 남기는 했습니다.
  - 개발이 되는 동안 이미지를 어떻게 처리할지 애매했습니다.
- 작업을 상당히 빠르게 끝냈 수 있을 것이라고 생각했습니다.
  - 모든 로직을 직접 만들면서 오히려 오래걸렸습니다.
- url로 상태를 표현 할 때는 클라이언트에서만 사용하기 때문에 쿼리 파라미터말고 해시를 사용했어야 합니다.
  - 쿼리 파라미터를 사용하면 url 객체를 사용할 때 set 객체처럼 사용할 수 있다는 장점이 있었습니다.
- MPA를 지향했다고 해도 DOM 처리를 SPA처럼 동적으로 DOM 요소를 생성하고 제거하려고 했습니다.
  - 올바른 방법은 css와 클래스 정도 변경해서 `display: none`을 활용했어야 할 것 같습니다.
  - 프로젝트를 작업하고나서 지금 레포를 다시봐도 어떤 html 구조를 갖고 있었어야 하는지 단번에 파악이 안 됩니다.
- main 페이지(`/`)에서 블로그 글 목록을 표시할 때 이것을 `meta.json`의 데이터를 받아서 SPA처럼 처리해서 보여주도록 했습니다.
  - 이런 것도 결국에는 빌드타임으로 옮기는 것이 충분히 가능한데 굳이 클라이언트에게 보내고 처리하도록 했습니다.

## neovim에서 cursor로 변경

- 어느정도 생산성이 기반이 되어야 합니다.
  - 원래 사용하던 neovim을 버려야 했습니다.
  - 직장에서 cursor를 사용했습니다. 처음에는 부정적이었는데 사용하면서 생각이 바뀌었습니다.
  - 회사에서 핵심적이지 않은 로직 작성을 AI에게 외주화가 가능해졌으면 로직을 고민하는 것보다 설계와 테스트를 잘하는 것이 더 이팩티브하지 않을까? 라는 피드백을 받았습니다.
  - 꽤 적절한 피드백입니다. MVP를 빨리 뽑기 위해 이팩티브한 방법이 맞습니다.
  - AI가 작성할 로직은 최대한 격리하고 테스트 가능한 방식으로 설계해서 작업한다면 원하는 결과를 빠르게 얻어내는 것이 가능하다는 생각이 들었습니다.
- AI가 모든 로직으 올바르게 작성할 것이라고 가정할 수 없습니다.
  - 로직이 틀렸다면 어떻게 로직이 틀릴 수 있는지 검증하는 것이더 효과적입니다.
- 직장을 다니고 취미도 생기면서 시간이 많이 없어졌습니다.
  - 정말 필요하다면 이직 준비를 위해 취미를 포기할 수 있습니다. ~~정말 그만두는 것은 아니고 오랫동안 쉴 가능성이 높습니다.~~
- 작업을 해보면서든 생각은 원래 회사에서 느껴야 했지만 AI에게 로직의 외주확 가능하겠다는 것입니다.
  - 더 정확히 소프트웨어 엔지니어링이라는 부분에서 프로그래밍이라는 부분을 외주화를 하게 됩니다.
  - 프로그래밍을 외주화하는 소프트웨어 엔지니어링에서는 무엇이 남는가? 이 부분을 고민해봐야 할 것 같습니다.
    - 소프트웨어 엔지니어링과 직접적으로 관련 된 부분은 설계, 테스트, 인프라, 소스관리(git), 코드 리뷰, 디버깅, ai가 작업할 개발 스펙관리 이런 부분들이 남습니다.
      - 실제 소스에 문제가 있고 ai를 신뢰할 수 없다면 개발자가 직접 코드를 확인해야 합니다.
      - 기능을 추가하면서 코드베이스에 엔트로피가 증가하는데 이를 최대한 줄일 수 있는 방향으로 끌고가야 합니다.
    - 소프트웨어 엔지니어링이 아닌 비즈니스에 더 집중해야 한다는 생각이 듭니다. 1인 개발자 시대가 맞다고 봅니다. 개발자가 PM이 되는가? 아니면 PM이 개발자가 되는가? 모호해진다는 생각이 들정도로 AI가 유용했습니다.
- 블로그를 만들기 위해 돈을 발라서 해결한 경우에 해당합니다. 이 블로그는 대략 26달러 정도 들었습니다. 크몽 외주를 생각해보면 저는 결과를 만족할 수 있었습니다.
- 요청 하나당 몇 백원단위라고 생각하면 상당한 신중함이 필요합니다. 물론 엄청난 프롬프트 퀄리티가 필요해야 이런 결과를 갖는 것은 아닙니다. 하지만 해결하고자 하는 것이 얼마나 좋은 비즈니스 가치를 갖는지 생각해야 합니다.
- 오늘 저는 26달러로 블로그를 만들었지만 이 블로그를 계속 유지하고 저의 생각을 표현하는 도구를 스스로 만들어 얻었다고 생각하면 저렴한 편입니다.
  - 투자 자금이라고 생각한다면 더욱더 적극적으로 블로그 글을 작성해야 할 이유가 생깁니다.
- 질문당 정말 비싸면 2달러 정도 합니다.
  - 여기서 2달러를 지불하고 정답지를 당장 확인할 수 있습니다. 물론 정답지는 다양하지만 당장 얻은 정답지입니다.
  - 2달러를 내고 하루를 아낄 수 있다고 생각하면 코딩은 저렴한데 제품개발은 비싼 취미라는 생각이 듭니다.
- 매달 16일이 되는 것을 기다려야 한다는 것이 아쉬워야 하는 것인지 아닌지 잘 모르겠습니다.
  - 토큰을 다 쓰면 DSA를 공부하고 토큰이 풍족하면 사이드 프로젝트를 진전시키면 될 것이라는 생각이 듭니다.

## 블로그 프로젝트 설계

- 코드베이스를 파악하기 위해 LLM에게 질문을 해야 한다고 하면 최대한 `app/build.ts`와 `app/client/index.ts` 2개를 설명해달라고 하기 바랍니다. 이 2개의 파일이 node.js에서 빌드를 처리하는 로직과 클라이언트에서 이벤트를 등록하는 부분 2가지라고 생각할 수 있습니다.
- 가능하면 최대한 적은 의존성으로 해결하고자 했습니다.
  - 의존성을 줄이고 직접 구현할 때마다 cursor의 토큰을 많이 사용해야 합니다. 각각의 엣지케이스를 본인이든 AI든 둘 중 하나가 처리해야 합니다.
- 파일 입출력은 테스트할 필요가 없습니다.
  - 입출력을 할 것인데 무슨 파일 이름으로 저장할지는 테스트할 가치가 있습니다.
  - 파일의 내용을 읽으면 어떻게 처리하는지 이 처리를 가장 많이 테스트해야 합니다.
    - 템플릿처리를 해주는 패키지를 설치할 수 있었지만 AI에게 시켰는데 알아서 잘 해주었습니다. 이 템플릿처리를 어떻게 할지 AI 보고 로직을 작성하게 만들고 테스트 코드도 작성하게 시켰습니다.
- 회사에서 모든 것을 테스트하겠다는 생각을 갖고 있던 사람이 있었습니다.
  - 얻은 교훈들이 있습니다.
    - 모든 것을 테스트하자고 요구한 사람은 테스트를 잘 모르는 사람입니다.
      - 모든것을 E2E 테스트로 처리하고자 했습니다. 실제 http 컨넥션가까디 다 테스트가 되어야 한다고 봤습니다.

### build 로직

```ts
/**
 * 모든 빌드 로직의 호출을 처리하는 함수
 *
 * 2단계 빌드 로직
 * 1. 마크다운 파일들 리스트업하기
 * 2. 리스트업된 파일들 읽고, 처리하고, html로 파일 쓰기
 *
 * 3계층 구조를 유지하고자 함
 * 1. 마크다운 파일 읽기 계층:
 *   - 마크 다운 파일들을 찾고 처리할 대상들을 기록함
 * 2. 마크다운 처리 및 html 변환 계층:
 *   - 마크다운 파일을 처리하고 html로 변환함
 * 3. html dist로 파일에 쓰기 계층:
 *   - 처리된 html 파일을 dist 폴더에 쓰기
 */
const build = async () => {
  // 길어서 생략
};

build();
```

- 최종 배포는 `build.ts`에서 `build` 함수 1개만 실행하도록 하는 것이 설계 의도입니다. 모든 것은 질렬적으로 추상화 없이 해결되어야 합니다. 아주 단순한 파일 읽기, 데이터 처리, 파일 쓰기 수준이 되어야 합니다.

#### 초기화 시점에 실행할 로직들

```ts
const metaJson: Metadata[] = [];

const appTemplate = await readFile(join(process.cwd(), 'app', 'templates', 'app.html'), 'utf8');
const postTemplate = await readFile(join(process.cwd(), 'app', 'templates', 'post.html'), 'utf8');
const mainTemplate = await readFile(join(process.cwd(), 'app', 'templates', 'main.html'), 'utf8');
const searchTemplate = await readFile(join(process.cwd(), 'app', 'templates', 'search.html'), 'utf8');

// /blogs의 모든 마크다운 파일 가져오기
const blogsDir = join(process.cwd(), 'blogs');

// dist 폴더 내용 초기화하기
await rm(join(process.cwd(), 'dist'), { recursive: true, force: true });
mkdirSync(join(process.cwd(), 'dist'), { recursive: true });

// asset 폴더 내용 복사하기
await cp(join(process.cwd(), 'app', 'asset'), join(process.cwd(), 'dist'), { recursive: true });

// client TypeScript를 JavaScript로 빌드하기
await esbuild.build({
  entryPoints: [join(process.cwd(), 'app', 'client', 'index.ts')],
  bundle: true,
  minify: true,
  outfile: join(process.cwd(), 'dist', 'script.js'),
  target: 'es2020',
  platform: 'browser',
});

// 메타 정보와 마크다운 콘텐츠를 저장할 맵 (파일 경로 기준)
const contentMap = new Map<string, string>();

// 깨진 이미지 링크 수집용 배열
const allBrokenImageLinks: BrokenImageLink[] = [];
const assetDir = join(process.cwd(), 'app', 'asset');
```

- 초기화는 극도로 단순합니다.
- 변수는 메타정보를 담을 배열 `metaJson`, 마크다운 문자열을 파일 경로랑 맵핑할 `contentMap`, 깨진 링크를 저장할 배열 `allBrokenImageLinks`를 선언합니다. 이 변수들은 데이터를 처리하면서 담기 위한 용도입니다.
- 빌드를 처리하면서 읽기만을 위해 템플릿으로 활용할 html 파일을 읽고 마크다운과 `asset` 경로에 해당하는 문자열을 초기화 합니다.
- 처리하는 행위는 `dist` 폴더를 비워버리고 `asset` 폴더의 이미지를 복사하고 클라이언트 런타임에서 실행할 로직을 타입스크립트에서 자바스크립트로 변환하고 `script.js`로 저장합니다.
- 여기서는 모두 node.js에서 제공하는 함수와 설차힌 esbuild 라이브러리 정도 활용했습니다.

#### 마크다운과 이미지 경로 리스트업

```ts
// /blogs의 모든 마크다운 파일 가져오기
const blogsDir = join(process.cwd(), 'blogs');
const markdownfiles = await listUpMarkdownFiles(blogsDir);

// blogs 폴더의 이미지 파일들을 dist로 복사 (폴더 구조 유지)
const imageFiles = await listUpImageFiles(blogsDir);
for (const imagePath of imageFiles) {
  // blogs/ 기준 상대 경로 유지
  const relativePath = imagePath.replace(`${blogsDir}/`, '');
  const destPath = join(process.cwd(), 'dist', relativePath);
  mkdirSync(dirname(destPath), { recursive: true });
  await cp(imagePath, destPath);
}
```

- 처리할 리스트업은 2가지입니다. 마크다운의 목록과 처리할 이미지 목록 정도 가져오고 처리하면 됩니다.
- 이미지 복사는 단순해서 바로 작성했습니다.
- 더 높은 수준을 갖게 만들고자 했으면 webp로 변환처리하는 로직을 넣는 것이지만 지금 굳이 하고 싶지 않습니다.

##### 폴더 구조

- 여기서 알아둘 점은 마크다운이 있는 폴더에 같이 활용할 이미지를 같이 넣었습니다. 빌드할 때 같은 폴더 구조를 유지하게 만들었습니다.
- 이것은 의도를 갖고 있습니다. 기존 프레임워크들은 마크다운과 이미지를 서로 다른 폴더에 넣어서 관리하도록 강제했습니다. 개발하면서 마음에 안 든 것은 이미지추가를 할 때 폴더를 별도로 관리해야 한다는 것이 불필요한 복잡성을 줬다고 생각이 들었습니다.

```
/root
  /content
    /blogs
      /2025-12-14
        /foo.md

  ...(생략)

  /public
    /asset
    /blogs
      /2025-12-14
        /bar.png
```

- `content/blogs/2025-12-14/foo.md`에 마크다운 글이 있고 `public/blogs/2025-12-14/bar.png`가 있다는 것이 서로 동떨어졌습니다.

```
/root
  /blogs
    /2025-12-14
      /foo.md
      /bar.png
```

- `blogs/2025-12-14/foo.md`와 `blog/2025-12-14/bar.png`로 보면 더 편할 것입니다. 저는 실제로 이 글에서만 해당하는 이미지인데 굳이 다른 파일에서 관리하는 것이 번거롭습니다.
  - 저는 위와 같은 형태의 폴더링이 더 자연스럽다고 봅니다.

##### 리스트업 로직

```ts
/**
 * @param dirPath 디렉토리 경로
 * @param baseDir 기본 디렉토리 경로
 * @returns 마크다운 파일 목록을 반환함
 */
const listUpMarkdownFiles = async (dirPath: string, baseDir: string = dirPath) => {
  const posts: { filePath: string; isProcessed: boolean }[] = [];

  const entries = await readdir(dirPath, { withFileTypes: true });

  for (const entry of entries) {
    const fullPath = join(dirPath, entry.name);

    if (entry.isDirectory()) {
      // 재귀적으로 하위 디렉토리 탐색
      const subPosts = await listUpMarkdownFiles(fullPath, baseDir);
      posts.push(...subPosts);
    } else if (entry.isFile() && path.extname(entry.name) === '.md') {
      posts.push({
        filePath: fullPath,
        isProcessed: false,
      });
    }
  }
  return posts;
};
```

- 마크다운 목록을 리스트업할 때는 DFS로 탐색을 합니다. stack 역할을 해주는 `post`도 있지만 `isDirectory` 메서드가 현재 본인이 경로라면 1 depth더 들어가라고 하는 로직이기 때문입니다.
- 하지만 파일이면 탐색을 중단하도록 만든겁니다.

```ts
// 이미지 확장자 목록
const IMAGE_EXTENSIONS = ['.png', '.jpg', '.jpeg', '.gif', '.svg', '.webp'];

/**
 * 지정된 디렉토리에서 이미지 파일을 재귀적으로 찾는 함수
 * @param dirPath 탐색할 디렉토리 경로
 * @returns 이미지 파일 경로 목록
 */
const listUpImageFiles = async (dirPath: string): Promise<string[]> => {
  const images: string[] = [];
  const entries = await readdir(dirPath, { withFileTypes: true });

  for (const entry of entries) {
    const fullPath = join(dirPath, entry.name);
    if (entry.isDirectory()) {
      images.push(...(await listUpImageFiles(fullPath)));
    } else if (IMAGE_EXTENSIONS.includes(extname(entry.name).toLowerCase())) {
      images.push(fullPath);
    }
  }
  return images;
};
```

- 이미지도 마크다운과 처리가 동일합니다.
- 물론 이미지 파일 이름을 이상하게 작성하면 push하지 말아야 할 것을 push하게 될 것입니다. 이런 버그는 상대할 가치가 없는 버그입니다.
  - 일반적이지 않은 행동 모두 대응해주는 것은 적절하지 않다고 봅니다.

#### 메타 정보 처리

#### 파일 읽기

- 초안에는 단 한번의 디스크 io로 처리 가능할 것이라고 생각했습니다. 검색 기능을 넣기 위해 각 글의 메타 정보를 모두 받고 메타정보를 모두 공유하게 해주려면 결국 디스크 io를 두번 할 수 밖에 없었습니다.
- 작업처리를 할 때 어느정도 계층 구조를 갖게 만들고자 했습니다.
  - 가장 먼저 처리하는 단계는 초기화 단계입니다. 실질적인 단계라고 치기에 애매합니다.
    - 메타정보를 담을 배열을 선언합니다.
    - 템플릿으로 활용할 html 파일을 읽습니다.
    - dist를 한번 비워버립니다.
    - 모든 html 파일들이 사용할 스크립트를 빌드합니다. `index.ts`가 해당합니다.
  - 첫번째는 처리해야할 작업들을 목록으로 정리해주는 작업입니다. 이것은 파일의 내용이 아니라 파일들의 주소를 알아내는 단계입니다.
    - 여기서 `listUpMarkdownFiles.ts`를 호출하고 처리합니다.
  - 두번째는 각 파일의 주소를 활용해 메티정보를 얻고 콘텐츠를 얻어 처리합니다.
    - 파일을 읽고 처리하고 쓰기만하면 될 것이라고 생각했습니다.
    - 실제로 한 것은 파일을 읽고 메타정보를 저장합니다. 마크다운 문자열도 이때 저장합니다. 나중에 Map의 사이즈가 너무 커져서 문제가 된다면 저장 안 하고 파일 읽기를 1번더 할 것입니다.
- blogs 폴더 내에서 모든 마크다운 파일들과 파일이 속한 폴더 주소를 알아내는 것이 1단계입니다.
  - 여기서는 모든 마크다운 파일 목록들을 알아내야 합니다.
  - 템플릿들을 모두 가져와야 합니다.
- 2단계는 파일과 폴더 주소를 활용해서 3단계 과정을 거칩니다.
  - 마크다운 파일을 읽습니다.
  - 마크다운 파일을 처리합니다.
    - 가장 많은 테스트 코드는 여기에 배치해야 합니다.
    - 템플릿들을 읽고 처리를 해줘야 합니다.
  - 마크다운 파일을 HTML로 저장합니다.
    - 처리가 완료된 html은 파일로 저장합니다.
      - 메타정보도 html의 header로 활용합니다.
    - 메타정보를 활용해서 json으로 저장합니다.
- 소프트웨어를 설계할 때 경계를 나누는 것이 중요한 활동이 됩니다.

### 클라이언트에게 전달할 로직

- 페이지를 로딩하고 이벤트를 등록하는 방식으로 처리했습니다.
- 이번에는 상태를 최대한 url에 넣었습니다.

### code block syntax highlighting

- 코드 블럭을 실제로 보고 읽고 이해를 합니다. 하지만 변수, 함수, 클래스, 연산자 등 눈으로 보고 구별이 안 되면 가독성을 떨어지는 문제가 있습니다.
- 코드 블럭을 그냥 보여주면 상당히 간지가 안 납니다.
- 가능하면 최대한 빌드 시점에 처리되게 만들고 싶습니다.
  - 유저는 최대한 의존성이 없는 순수한 html 위주로 전달받아야 한다고 보고 있습니다.
- https://shiki.style/
  - nuxt content가 사용하는 것으로 보입니다.

## 바뀐 github action

- 이전에 nuxt로 작성했던 yml을 다시 작성해야 합니다. ~~트래픽도 없는 블로그 주제에 한번에 잘 작성하고 싶습니다.~~
- https://ko.vite.dev/guide/static-deploy 도 참고하기는 했습니다.
- ChatGPT에게 초안 작성을 요구했지만 RAG 모델이 아니라서 신뢰할 수 없었습니다. 하지만 좋은 초안은 맞는 것 같습니다.
- 이짓 거리를 할 때 쯤에 Opus에 빠른 요청을 보낼 수 있는 토큰을 소진했습니다. 한편으로 다행입니다. 돈을 더 쓰고 싶다는 생각이 들때가 있습니다.

```yml
# https://github.com/actions/deploy-pages#usage
name: Deploy to GitHub Pages
on:
  workflow_dispatch:
  push:
    branches:
      - main
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: corepack enable
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
      # Pick your own package manager and build script
      - run: pnpm install
      - run: pnpm generate --preset github_pages
      - run: touch .output/public/.nojekyll
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./.output/public
  # Deployment job
  deploy:
    # Add a dependency to the build job
    needs: build
    # Grant GITHUB_TOKEN the permissions required to make a Pages deployment
    permissions:
      pages: write # to deploy to Pages
      id-token: write # to verify the deployment originates from an appropriate source
    # Deploy to the github_pages environment
    environment:
      name: github_pages
      url: ${{ steps.deployment.outputs.page_url }}
    # Specify runner + deployment step
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
```

- 이게 기존에 작성되어 있던 배포 yml입니다.
- nuxt와 관련된 내용을 제거하고 순수하게 node.js 정도만 남겨야 합니다.
- 작년에 작업하고 내용을 너무 많이 까먹어서 다시 찾아 봐야 합니다.

```yml
name: Deploy to GitHub Pages

on:
  push:
    branches:
      - main

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: pages
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 24
          cache: pnpm

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build
        run: pnpm run build

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: dist

  deploy:
    runs-on: ubuntu-latest
    needs: build
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
```

- 이번에 해볼 활동은 라인바이 라인으로 해석하는 것을 시도할 것입니다.

### actions/checkout은 무엇인가?

- `actions/checkout@v4`이 무슨 의미인지 몰라 검색했습니다.
- https://www.daleseo.com/github-actions-checkout/

```sh
git init # 명령어를 통해 작업 디렉토리를 로컬 저장소로 만든다.
git config # 명령어를 통해 각종 인증 관련 정보를 설정한다
git fetch # 명령어를 통해 원격 저장소로 부터 코드를 받아온다.
git checkout # 명령어를 통해 주(main) 브랜치로 전환한다.
git log # 명령어로 마지막 커밋(commit)의 해시값을 확인한다.
```

- 위에 해당하는 명령들을 실행한다고 합니다. 지금 보여주는 것은 간략한 버전일 것입니다.
- `actions/setup-node@v4`인데 이것이 검색을 하면서 다음 내용들을 알아냈습니다.
  - https://github.com/marketplace/actions/setup-node-js-environment
  - https://github.com/actions/setup-node

```yml
- uses: actions/checkout@v5
- uses: actions/setup-node@v6
  with:
    node-version: 24
```

- `READMD.md`에 확인한 시점에는 위를 예시로 보여주고 있습니다.
- 위처럼 하면 일단 node.js와 npm이 설치 됩니다.

```yml
on:
  - push
  - pull_request

jobs:
  cache-and-install:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - uses: pnpm/action-setup@v4
        name: Install pnpm
        with:
          version: 10
          cache: true

      - name: Install dependencies
        run: pnpm install
```

- https://github.com/pnpm/action-setup
- https://github.com/marketplace/actions/setup-pnpm
- 위에 알려준 버전을 사용하면 pnpm 10 버전을 사용할 수 있습니다.

## 고민한 것들

- 일생동안 약 4000개가 안 될 블로그 글을 작성하는데 모두 메모리에 올려서 처리하지 않으려고 고민하고 있습니다.
- 실제 존재하지 않는 문제를 해결하려고 고민하는 것인지 의문입니다.
- 마크다운 파일 1개 읽는데 그렇게 크지 않습니다.
- 다시 생각해도 디스크에서 같은 파일을 2번 읽어서 메모리 사용량을 줄이는 것이 더 안정적일 것 같습니다.
- 중간에 설계를 변경하는 것이 더 적절할 것 같습니다.
  - 메타정보를 읽고 처리하는 단계가 있어야 합니다.
  - 그 후에 파일 쓰기를 처리하는 단계가 있어야 합니다.
  - 각각의 블로그 글 별로 검색 기능이 지원되기 위해서는 이렇게 처리해야 합니다.

## 개발을 진행하면서 사용하기 시작한 툴

- lazygit은 터미널에서 작업할 때 많이 사용했는데 cursor 터미널에서도 사용하고 있습니다.
  - cursor의 커밋 관련 기능은 단축키로 킬 수 있지만 결국 무엇을 추가하고 삭제할지 마우스로 제어가 필요했습니다.
  - github 데스크탑은 회사에서 사용하지만 기능이 너무 제한적이었습니다. 또 마우스를 클릭하기 위한 노력이 필요했습니다.
  - 마우스를 사용하지 않으면서 무엇을 커밋에 올리고 말고 또 github 데스크탑보다 기능이 많은 lazygit이 편리했습니다.
- yazi를 사용하기 시작했습니다.
  - 개발자 블로그에서 이미지를 넣었을 때 전에는 그냥 링크를 활용했었습니다. 하지만 어느날 github의 정책 변경 시점 이후로 url 주소가 계속 바뀌었습니다.
  - github 이슈 자체가 이미지 스토리지로 사용하기 어려워졌습니다. 이런 이유로 이미지를 커밋에 올리기로 했습니다.
  - 이미지를 커밋으로 관리하면 무슨 폴더에 속해야 하는지 관리가 필요하고 이를 이동시키는 작업에 yazi가 적절했습니다.
  - 파일을 드래그앤 드롭하기에는 너무 글과 이미지가 너무 많아졌습니다.

## 배운 것

- AI 회의론이 강했던 저의 생각을 바꿀 수 있었습니다.
- 어려운 로직을 아주 잘 짜는 것보다 설계를 잘 하는 것이 더 이팩티브합니다.
  - AI로 작성된 로직을 테스트하기 쉬운 코드인가?
    - 파일 읽기, 파일 쓰기를 테스트할 범위에서 제외하고 처리 로직에 최대한 몰아버릴 수 없는가?
- 리뷰하는 스킬이 중요해 보입니다.
  - AI로 로직 작성을 하면서 여전히 처리부에 있어야할 로직이 마지막 쓰기에 위치하는 경우가 많았습니다. 원하는 결과는 얻어도 유지보수를 위해 테스트하기 쉬운 구조로 수정해달라고 요구해야 합니다.
- 회사랑 동일하게 git을 효과적으로 사용할 줄 알아야 합니다.
  - 마음에 드는 기능 일부는 커밋으로 남기고 마음에 안드는 부분을 다시 작성해달라고 해야 합니다.
  - lazygit을 활용해서 브라우저 접속을 제외하고 마우스 없는 개발을 지향할 수 있고 지향해야 합니다.
- 확실히 지금 개발자 블로그 프로젝트는 그린필드 프로젝트라서 LLM 성능이 상당히 좋습니다.
- AI가 작성해준 코드인데 코드 퀄리티가 평균이라고 보면 이 평균이라는 것 허들은 상당히 높습니다.
  - 물론 코드 퀄리티에서 기능과 관련된 퀄리티입니다. 설계와 디버깅은 휴먼인더 루프를 반드시 의존할 수 밖에 없었습니다.

## 앞으로 해볼 작업

- fuse.js로 클라이언트에서 검색 퀄리티 높이기
  - 지금까지 모두 개발의존성(devDependencies)인데 런타임에 필요한 의존성(dependencies)을 처음으로 추가해야 한다는 것이 고민입니다.
- webp로 변환처리
  - 이미지를 더 경량화 시킬 수 있을 것입니다. 새로고침 혹은 태그를 누를 때마다 새로고침이 발생하는데 이미지가 느려서 깜빡이는 현상을 막고 싶습니다.
- e2e 테스트로 깨진 이미지를 발견
